{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojnQWIZulDLG",
        "outputId": "1ecd51e9-5e92-43ba-de46-8aeeb2056206"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------------+---------------------+----------+---------+---------+\n",
            "| id | experiment |    particle_type    |    x     |    y    |    z    |\n",
            "+----+------------+---------------------+----------+---------+---------+\n",
            "| 0  |   TS_5_4   |     beta-amylase    | 2983.596 | 3154.13 | 764.124 |\n",
            "| 1  |   TS_5_4   |  beta-galactosidase | 2983.596 | 3154.13 | 764.124 |\n",
            "| 2  |   TS_6_4   |       ribosome      | 2983.596 | 3154.13 | 764.124 |\n",
            "| 3  |   TS_6_4   |     apo-ferritin    | 2983.596 | 3154.13 | 764.124 |\n",
            "| 4  |  TS_69_2   | virus-like-particle | 2983.596 | 3154.13 | 764.124 |\n",
            "| 5  |   TS_5_4   |     beta-amylase    | 2983.596 | 3154.13 | 764.124 |\n",
            "| 6  |   TS_5_4   |  beta-galactosidase | 2983.596 | 3154.13 | 764.124 |\n",
            "| 7  |   TS_6_4   |       ribosome      | 2983.596 | 3154.13 | 764.124 |\n",
            "| 8  |   TS_6_4   |     apo-ferritin    | 2983.596 | 3154.13 | 764.124 |\n",
            "| 9  |  TS_69_2   | virus-like-particle | 2983.596 | 3154.13 | 764.124 |\n",
            "+----+------------+---------------------+----------+---------+---------+\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from prettytable import PrettyTable\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ----------------------------\n",
        "# Submission Generation Utils\n",
        "# ----------------------------\n",
        "def generate_submission(predictions, experiment_ids, particle_types, output_file=\"submission.csv\"):\n",
        "    if not (len(predictions) == len(experiment_ids) == len(particle_types)):\n",
        "        raise ValueError(\"Input lists must have the same length.\")\n",
        "\n",
        "    results = []\n",
        "    for idx, (pred, experiment, particle_type) in enumerate(zip(predictions, experiment_ids, particle_types)):\n",
        "        if isinstance(pred, tuple) and len(pred) == 3:\n",
        "            x, y, z = pred\n",
        "        else:\n",
        "            raise ValueError(\"Each prediction must be a tuple of three floats (x, y, z).\")\n",
        "\n",
        "        results.append({\n",
        "            \"id\": idx,\n",
        "            \"experiment\": experiment,\n",
        "            \"particle_type\": particle_type,\n",
        "            \"x\": x,\n",
        "            \"y\": y,\n",
        "            \"z\": z\n",
        "        })\n",
        "\n",
        "    submission_df = pd.DataFrame(results)\n",
        "    submission_df.to_csv(output_file, index=False)\n",
        "\n",
        "# ----------------------------\n",
        "# Dataset Class\n",
        "# ----------------------------\n",
        "class CryoETDataset(Dataset):\n",
        "    def __init__(self, data, labels=None, augment=False):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.data[idx]\n",
        "        y = self.labels[idx] if self.labels is not None else None\n",
        "        if self.augment:\n",
        "            x = self.augment_data(x)\n",
        "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.long) if y is not None else None\n",
        "\n",
        "    def augment_data(self, x):\n",
        "        if torch.rand(1).item() > 0.5:\n",
        "            x = x.flip(dims=[0])\n",
        "        return x\n",
        "\n",
        "# ----------------------------\n",
        "# Model Definition\n",
        "# ----------------------------\n",
        "class CryoETModel(nn.Module):\n",
        "    def __init__(self, num_classes=5):\n",
        "        super(CryoETModel, self).__init__()\n",
        "        self.conv1 = nn.Conv3d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv3d(32, 64, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(64 * 16 * 16 * 16, 128)  # Adjust if your input size changes\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.max_pool3d(x, 2)\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = torch.max_pool3d(x, 2)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "# ----------------------------\n",
        "# Training & Evaluation\n",
        "# ----------------------------\n",
        "def train_model(model, train_loader, val_loader, num_epochs=10, lr=0.001):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for x, y in tqdm(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x)\n",
        "            loss = criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        val_accuracy = evaluate_model(model, val_loader)\n",
        "        if val_accuracy > best_accuracy:\n",
        "            best_accuracy = val_accuracy\n",
        "            torch.save(model.state_dict(), \"best_model.pth\")\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Train Loss: {train_loss/len(train_loader):.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "def evaluate_model(model, data_loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in data_loader:\n",
        "            outputs = model(x)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += y.size(0)\n",
        "            correct += (predicted == y).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "def calculate_fbeta(y_true, y_pred, beta=4):\n",
        "    return fbeta_score(y_true, y_pred, beta=beta, average='micro')\n",
        "\n",
        "# ----------------------------\n",
        "# Submission Preparation\n",
        "# ----------------------------\n",
        "def prepare_submission(model, test_loader, output_file=\"/content/submission.csv\"):\n",
        "    model.eval()\n",
        "    results = []\n",
        "    with torch.no_grad():\n",
        "        for i, (x, _) in enumerate(test_loader):\n",
        "            outputs = model(x)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            for idx, pred in enumerate(predicted):\n",
        "                results.append({\n",
        "                    \"id\": i * len(predicted) + idx,\n",
        "                    \"experiment\": \"TS_5_4\",\n",
        "                    \"particle_type\": [\"ribosome\", \"virus-like\", \"apo-ferritin\", \"thyroglobulin\", \"Î²-galactosidase\"][pred],\n",
        "                    \"x\": np.random.uniform(),\n",
        "                    \"y\": np.random.uniform(),\n",
        "                    \"z\": np.random.uniform()\n",
        "                })\n",
        "\n",
        "    submission_df = pd.DataFrame(results)\n",
        "    submission_df.to_csv(output_file, index=False)\n",
        "\n",
        "submission_df = pd.read_csv(\"/content/submission.csv\")\n",
        "# Display first 10 rows using PrettyTable\n",
        "table = PrettyTable()\n",
        "table.field_names = submission_df.columns.tolist()\n",
        "for _, row in submission_df.head(10).iterrows():\n",
        "    table.add_row(row.tolist())\n",
        "print(table)"
      ]
    }
  ]
}