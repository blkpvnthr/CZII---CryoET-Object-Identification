{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05b29b0d-cb37-49b0-a05f-c5e117c6942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "Dataset = '/data/czii-cryo-et-object-identification/test/static/ExperimentRuns/'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def generate_submission(predictions, experiment_ids, particle_types, output_file=\"submission.csv\"):\n",
    "    # Validate input lengths\n",
    "    if not (len(predictions) == len(experiment_ids) == len(particle_types)):\n",
    "        raise ValueError(\"Input lists must have the same length.\")\n",
    "\n",
    "    # Initialize results list for submission data\n",
    "    results = []\n",
    "    \n",
    "    # Iterate over each prediction to format the output\n",
    "    for idx, (pred, experiment, particle_type) in enumerate(zip(predictions, experiment_ids, particle_types)):\n",
    "        if isinstance(pred, tuple) and len(pred) == 3:\n",
    "            x, y, z = pred\n",
    "        else:\n",
    "            raise ValueError(\"Each prediction must be a tuple of three floats (x, y, z).\")\n",
    "        \n",
    "        # Append to results\n",
    "        results.append({\n",
    "            \"id\": idx,\n",
    "            \"experiment\": experiment,\n",
    "            \"particle_type\": particle_type,\n",
    "            \"x\": x,\n",
    "            \"y\": y,\n",
    "            \"z\": z\n",
    "        })\n",
    "\n",
    "    # Convert results to DataFrame and save as CSV\n",
    "    submission_df = pd.DataFrame(results)\n",
    "    submission_df.to_csv(output_file, index=False)\n",
    "\n",
    "# Example usage\n",
    "predictions = [(2983.596, 3154.13, 764.124)] * 10\n",
    "experiment_ids = [\"TS_5_4\", \"TS_5_4\", \"TS_6_4\", \"TS_6_4\", \"TS_69_2\"] * 2\n",
    "particle_types = [\"beta-amylase\", \"beta-galactosidase\", \"ribosome\", \"apo-ferritin\", \"virus-like-particle\"] * 2\n",
    "\n",
    "generate_submission(predictions, experiment_ids, particle_types)\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class CryoETDataset(Dataset):\n",
    "    def __init__(self, data, labels=None, augment=False):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        if self.labels is not None:\n",
    "            y = self.labels[idx]\n",
    "        else:\n",
    "            y = None\n",
    "\n",
    "        if self.augment:\n",
    "            x = self.augment_data(x)\n",
    "\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.long) if y is not None else None\n",
    "\n",
    "    def augment_data(self, x):\n",
    "        if torch.rand(1).item() > 0.5:\n",
    "            x = x.flip(dims=[0])  # Example augmentation, flipping along one dimension\n",
    "        return x\n",
    "\n",
    "        \n",
    "class CryoETModel(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(CryoETModel, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv3d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64*16*16*16, 128)  # Adjust dimensions according to your input size\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool3d(x, kernel_size=2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool3d(x, kernel_size=2)\n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        \n",
    "def train_model(model, train_loader, val_loader, num_epochs=10, lr=0.001):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x, y in tqdm(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        val_accuracy = evaluate_model(model, val_loader)\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {train_loss/len(train_loader)}, Val Accuracy: {val_accuracy}\")\n",
    "\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in data_loader:\n",
    "            outputs = model(x)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "def calculate_fbeta(y_true, y_pred, beta=4):\n",
    "    return fbeta_score(y_true, y_pred, beta=beta, average='micro')\n",
    "\n",
    "def prepare_submission(model, test_loader, output_file=\"submission.csv\"):\n",
    "    model.eval()\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for i, (x, _) in enumerate(test_loader):\n",
    "            outputs = model(x)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            for idx, pred in enumerate(predicted):\n",
    "                results.append({\n",
    "                    \"id\": i * len(predicted) + idx,\n",
    "                    \"experiment\": \"TS_5_4\",\n",
    "                    \"particle_type\": [\"ribosome\", \"virus-like\", \"apo-ferritin\", \"thyroglobulin\", \"Î²-galactosidase\"][pred],\n",
    "                    \"x\": np.random.uniform(),  # Placeholder: Use model's output or additional processing to set coordinates\n",
    "                    \"y\": np.random.uniform(),\n",
    "                    \"z\": np.random.uniform()\n",
    "                })\n",
    "    \n",
    "    submission_df = pd.DataFrame(results)\n",
    "    submission_df.to_csv(output_file, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b9717d-64eb-4232-b0ce-c4c5d4bd6ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
